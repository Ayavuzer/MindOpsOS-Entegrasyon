# E12-S1: Pipeline Runs Table Migration

**Epic:** E12 - Database  
**Story Points:** 1  
**Status:** Review  
**Sprint:** 2  

---

## User Story

**As a** developer  
**I want** pipeline_runs table created  
**So that** pipeline history is persisted  

---

## Acceptance Criteria

1. ✅ **AC1:** pipeline_runs table exists
2. ✅ **AC2:** Stores all pipeline run stats
3. ✅ **AC3:** Tenant-aware with tenant_id
4. ✅ **AC4:** Indexes for fast queries

---

## Tasks / Subtasks

- [x] Task 1: Create migration SQL file
- [x] Task 2: Execute migration on database
- [x] Task 3: Update service to use new table

---

## File List

### Migrations

- `migrations/20251228_001_processing_logs.sql` - Created

### Backend

- `apps/api/processing/service.py` - Updated to use pipeline_runs

---

## Database Table

```sql
CREATE TABLE pipeline_runs (
    id SERIAL PRIMARY KEY,
    tenant_id INTEGER NOT NULL REFERENCES tenants(id),
    started_at TIMESTAMPTZ NOT NULL,
    completed_at TIMESTAMPTZ NOT NULL,
    booking_emails_fetched INTEGER DEFAULT 0,
    stopsale_emails_fetched INTEGER DEFAULT 0,
    reservations_parsed INTEGER DEFAULT 0,
    stop_sales_parsed INTEGER DEFAULT 0,
    reservations_synced INTEGER DEFAULT 0,
    stop_sales_synced INTEGER DEFAULT 0,
    success BOOLEAN DEFAULT true,
    message TEXT,
    errors TEXT[] DEFAULT '{}',
    created_at TIMESTAMPTZ DEFAULT NOW()
);
```

### Indexes

- `idx_pipeline_runs_tenant_id`
- `idx_pipeline_runs_started_at`

---

## Dev Agent Record

### Agent Model Used

Antigravity

### Completion Notes

- Created pipeline_runs (not processing_logs which has different schema)
- Added parsed stats columns
- Indexes for tenant and time-based queries
- Updated ProcessingService to log to new table
